{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REuW783_MQYo"
      },
      "source": [
        "# AS262 - Projects\n",
        "\n",
        "# Photometric Redshift Calculation\n",
        "\n",
        "## Background / Motivation\n",
        "\n",
        "A photometric redshift is an estimate for the recession velocity of a galaxy made without measuring its spectrum.  Instead the technique uses photometry and broad-band colors to estimate the galaxies redshift.  Using photometric redshifts to estimate the distances of faint galaxies has become an integral part of galaxy surveys conducted during recent years. This is driven by the large number of galaxies and their faint fluxes, which have made spectroscopic follow-up infeasible except for a relatively small and bright fraction of the galaxy population. Albeit less precise and less accurate than spectroscopy, photometric redshifts provide a way to estimate distances for galaxies too faint for spectroscopy or samples too large to be practical for complete spectroscopic coverage.\n",
        "\n",
        "## Project Outline:\n",
        "* Use supervised classification to determine the redshift of galaxies based on their broad band photometry.\n",
        "\n",
        "\n",
        "* The data used for this project will come from the [CEERS surey](https://ceers.github.io), which imaged a region of sky known as the Extended Groth Strip with JWST.  The photometry data is stored in an hdf5 file (similar to the fits table we used in Lecture 3 UVJ exercise, and read in with exactly the same routine, using astropy.table.Table).  This file will be made available on Filer.  Please note that the photometry data has not been published, so it should be considered proprietary for the time being.  I am allowing students to use this data since I am a member of the CEERS collaboration, and you can gain access to it through me.\n",
        "\n",
        "\n",
        "* You'll most likely want to limit your analysis to relatively bright and/or massive galaxies.  This might mean only working with galaxies whose F356W magnitude is less than 26.5 and/or mass greater than $10^8 M_\\odot$.  You should vary these cuts to determine how they affect the final results.\n",
        "\n",
        "\n",
        "* Youâ€™ll need to group the photometry as features in a single `X` array in the format that Scikit-Learn wants and then split the array into a training and test dataset using the `split_samples` routine, which we encountered in Lecture 16. The \"known\" redshifts come from spectroscopy, given in the table as 'z_spec'.  Note that not all galaxies have spectroscopy, so your training set can only use a subset of the full dataset.  You could perform cross-validation on some subset of this, and then apply your model to the remaining data and compare to the team's photometric redshifts (given as 'ZA_finkelstein' or 'z_phot').\n",
        "\n",
        "\n",
        "* Try **at least two** supervised classification algorithms and compare their effectiveness by plotting the true redshift against the predicted redshift.  The plot should look something similar to this (although the table I'm providing you doesn't list different quality flags for the spectroscopic redshifts, so all data points would be the same color):\n",
        "\n",
        "\n",
        "<img src=https://www.colby.edu/physics/faculty/mcgrath/AS262/photoz.png width=\"500\">\n",
        "\n",
        "\n",
        "* A quantitative measure of how well the classifier is working can be calculated using the Normalized Median Absolute Deviation:\n",
        "\n",
        "$$ \\sigma_{\\rm NMAD} = 1.48\\times {\\rm median}\\left(\\frac{|\\Delta z|}{1+z_{rm true}}\\right) $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* Potential classification algorithms include:\n",
        "    * Decision Tree Classifier (`sklearn.tree.DecisionTreeRegressor`)\n",
        "    * Random Forest Classifier (`sklearn.ensemble.RandomForestRegressor`)\n",
        "    * K-Neighbors Classifier (`sklearn.neighbors.KNeighborsRegressor`)\n",
        "    * Support Vector Machine (`sklearn.svm.SVR`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee-melxNMQYq"
      },
      "source": [
        "## Example\n",
        "\n",
        "Here's an example of using a Decision Tree Regression to calculate the photometric redshift of galaxies in the SDSS dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install astroML"
      ],
      "metadata": {
        "id": "VJAcMG4UINnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxbRggEIMQYq"
      },
      "outputs": [],
      "source": [
        "# Author: Jake VanderPlas\n",
        "# License: BSD\n",
        "#   The figure produced by this code is published in the textbook\n",
        "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
        "#   For more information, see http://astroML.github.com\n",
        "#   To report a bug or issue, use the following forum:\n",
        "#    https://groups.google.com/forum/#!forum/astroml-general\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "# import seaborn as sns; sns.set()\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from astroML.datasets import fetch_sdss_specgals\n",
        "\n",
        "#----------------------------------------------------------------------\n",
        "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
        "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
        "# result in an error if LaTeX is not installed on your system.  In that case,\n",
        "# you can set usetex to False.\n",
        "if \"setup_text_plots\" not in globals():\n",
        "    from astroML.plotting import setup_text_plots\n",
        "setup_text_plots(fontsize=8, usetex=False)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# Fetch data and prepare it for the computation\n",
        "data = fetch_sdss_specgals()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tE_oTN9MQYq"
      },
      "outputs": [],
      "source": [
        "# put magnitudes in a matrix\n",
        "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
        "z = data['z']\n",
        "\n",
        "# train on ~60,000 points\n",
        "mag_train = mag[::10]\n",
        "z_train = z[::10]\n",
        "\n",
        "# test on ~6,000 separate points\n",
        "mag_test = mag[1::100]\n",
        "z_test = z[1::100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQSu_82nMQYr"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Compute the cross-validation scores for several tree depths\n",
        "depth = np.arange(1, 21)\n",
        "rms_test = np.zeros(len(depth))\n",
        "rms_train = np.zeros(len(depth))\n",
        "i_best = 0\n",
        "z_fit_best = None\n",
        "\n",
        "for i, d in enumerate(depth):\n",
        "    clf = DecisionTreeRegressor(max_depth=d, random_state=0)\n",
        "    clf.fit(mag_train, z_train)\n",
        "\n",
        "    z_fit_train = clf.predict(mag_train)\n",
        "    z_fit = clf.predict(mag_test)\n",
        "    rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
        "    rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
        "\n",
        "    if rms_test[i] <= rms_test[i_best]:\n",
        "        i_best = i\n",
        "        z_fit_best = z_fit\n",
        "\n",
        "best_depth = depth[i_best]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kskCEW7iMQYr"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Plot the results\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "fig.subplots_adjust(wspace=0.25,\n",
        "                    left=0.1, right=0.95,\n",
        "                    bottom=0.15, top=0.9)\n",
        "\n",
        "# first panel: cross-validation\n",
        "ax = fig.add_subplot(121)\n",
        "ax.plot(depth, rms_test, '-k', label='cross-validation')\n",
        "ax.plot(depth, rms_train, '--k', label='training set')\n",
        "ax.set_xlabel('depth of tree', size=20)\n",
        "ax.set_ylabel('rms error', size=20)\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
        "ax.set_xlim(0, 21)\n",
        "ax.set_ylim(0.009,  0.04)\n",
        "ax.legend(loc=1, fontsize='large')\n",
        "\n",
        "# second panel: best-fit results\n",
        "ax = fig.add_subplot(122)\n",
        "edges = np.linspace(z_test.min(), z_test.max(), 101)\n",
        "H, zs_bins, zp_bins = np.histogram2d(z_test, z_fit_best, bins=edges)\n",
        "ax.imshow(H.T, origin='lower', interpolation='nearest', aspect='auto',\n",
        "           extent=[zs_bins[0], zs_bins[-1], zs_bins[0], zs_bins[-1]],\n",
        "           cmap=plt.cm.binary)\n",
        "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
        "ax.text(0.04, 0.96, \"depth = %i\\nrms = %.3f\" % (best_depth, rms_test[i_best]),\n",
        "        ha='left', va='top', transform=ax.transAxes, size=12)\n",
        "ax.set_xlabel(r'$z_{\\rm true}$', size=20)\n",
        "ax.set_ylabel(r'$z_{\\rm fit}$', size=20)\n",
        "\n",
        "ax.set_xlim(-0.02, 0.4001)\n",
        "ax.set_ylim(-0.02, 0.4001)\n",
        "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ha5PZOV_KKKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWuiQqMaMQYr"
      },
      "source": [
        "Some preliminaries to get you started using the CEERS dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MvsZPmlMQYr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from astropy.table import Table\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdq28hl0MQYs"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    photometry_data_path = \"/content/drive/MyDrive/Colab Notebooks/ceers_all_v0.51_eazy.hdf5\"\n",
        "    photometry_data_container = Table.read(photometry_data_path)\n",
        "    # print(photometry_data_container.columns)\n",
        "\n",
        "except Exception as error_1:\n",
        "    print(f\" { type(error_1).__name__ } occured! \")\n",
        "\n",
        "\n",
        "def processed_data():\n",
        "\n",
        "    z_spec = photometry_data_container['z_spec']\n",
        "    log_mass = photometry_data_container['fast_lmass']\n",
        "    flux_115_magnitude = -2.5*np.log10(photometry_data_container['FLUX_115'])+31.4 # had conversion aid from Prof McGrath\n",
        "    flux_150_magnitude = -2.5*np.log10(photometry_data_container['FLUX_150'])+31.4\n",
        "    flux_200_magnitude = -2.5*np.log10(photometry_data_container['FLUX_200'])+31.4\n",
        "    flux_277_magnitude = -2.5*np.log10(photometry_data_container['FLUX_277'])+31.4\n",
        "    flux_356_magnitude = -2.5*np.log10(photometry_data_container['FLUX_356'])+31.4\n",
        "    flux_410_magnitude = -2.5*np.log10(photometry_data_container['FLUX_410'])+31.4\n",
        "    flux_444_magnitude = -2.5*np.log10(photometry_data_container['FLUX_444'])+31.4\n",
        "    flux_606_magnitude = -2.5*np.log10(photometry_data_container['FLUX_606'])+31.4\n",
        "    flux_814_magnitude = -2.5*np.log10(photometry_data_container['FLUX_814'])+31.4\n",
        "    flux_125_magnitude = -2.5*np.log10(photometry_data_container['FLUX_125'])+31.4\n",
        "\n",
        "\n",
        "    # we perform the first series of feature extraction here based on the brightness of the galaxy using flux_356 < 26.5\n",
        "    flux_356_magnitude = -2.5*np.log10(photometry_data_container['FLUX_356'])+31.4\n",
        "    mask_from_flux = flux_356_magnitude < 26.5 # this is for the first round of data cleaning.\n",
        "    # print(mask_for_flux)\n",
        "    # print(flux_356_magnitude)\n",
        "\n",
        "    new_z_spec = z_spec[mask_from_flux]\n",
        "    new_log_mass = log_mass[mask_from_flux]\n",
        "    new_flux_115_magnitude = flux_115_magnitude[mask_from_flux]\n",
        "    new_flux_150_magnitude = flux_150_magnitude[mask_from_flux]\n",
        "    new_flux_200_magnitude = flux_200_magnitude[mask_from_flux]\n",
        "    new_flux_277_magnitude = flux_277_magnitude[mask_from_flux]\n",
        "    new_flux_356_magnitude = flux_356_magnitude[mask_from_flux]\n",
        "    new_flux_410_magnitude = flux_410_magnitude[mask_from_flux]\n",
        "    new_flux_444_magnitude = flux_444_magnitude[mask_from_flux]\n",
        "    new_flux_606_magnitude = flux_606_magnitude[mask_from_flux]\n",
        "    new_flux_814_magnitude = flux_814_magnitude[mask_from_flux]\n",
        "    new_flux_125_magnitude = flux_125_magnitude[mask_from_flux]\n",
        "\n",
        "\n",
        "    # now, we perfomr the remainder of the feature extraction based on the z_spec, extracting only features for galaxies with z_spec not equal to -99 or -1.\n",
        "    # the first feature we'd want to extract is the true spectroscopic redshift z_spec from which we'll discard galaxies with redshits equal to -99 or -1\n",
        "\n",
        "    mask_from_z_spec = ~( (new_z_spec == -99) | (new_z_spec == -1) )\n",
        "\n",
        "    desired_z_spec = new_z_spec[mask_from_z_spec]\n",
        "    desired_log_mass = new_log_mass[mask_from_z_spec]\n",
        "    desired_flux_115_magnitude = new_flux_115_magnitude[mask_from_z_spec]\n",
        "    desired_flux_150_magnitude = new_flux_150_magnitude[mask_from_z_spec]\n",
        "    desired_flux_200_magnitude = new_flux_200_magnitude[mask_from_z_spec]\n",
        "    desired_flux_277_magnitude = new_flux_277_magnitude[mask_from_z_spec]\n",
        "    desired_flux_356_magnitude = new_flux_356_magnitude[mask_from_z_spec]\n",
        "    desired_flux_410_magnitude = new_flux_410_magnitude[mask_from_z_spec]\n",
        "    desired_flux_444_magnitude = new_flux_444_magnitude[mask_from_z_spec]\n",
        "    desired_flux_606_magnitude = new_flux_606_magnitude[mask_from_z_spec]\n",
        "    desired_flux_814_magnitude = new_flux_814_magnitude[mask_from_z_spec]\n",
        "    desired_flux_125_magnitude = new_flux_125_magnitude[mask_from_z_spec]\n",
        "\n",
        "\n",
        "    desired_z_phot = (photometry_data_container['z_phot'][mask_from_flux])[mask_from_z_spec]\n",
        "    desired_z_phot_finkelstein = (photometry_data_container['ZA_finkelstein'][mask_from_flux])[mask_from_z_spec]\n",
        "\n",
        "    X = np.vstack([desired_log_mass, desired_flux_115_magnitude, desired_flux_150_magnitude, desired_flux_200_magnitude, desired_flux_277_magnitude, desired_flux_356_magnitude, desired_flux_410_magnitude, desired_flux_444_magnitude, desired_flux_606_magnitude, desired_flux_814_magnitude, desired_flux_125_magnitude]).T\n",
        "    # print(X[:,0].shape)\n",
        "    y = np.array(desired_z_spec)\n",
        "    # print(f\" The shape of desired_z_spec is {desired_z_spec.shape}\")\n",
        "    # print(f\" The shape of desired_z_phot is {desired_z_phot.shape}\")\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    return X, y, desired_z_phot, desired_z_phot_finkelstein\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual Analysis."
      ],
      "metadata": {
        "id": "gMh-boWzEgx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n"
      ],
      "metadata": {
        "id": "xDXWwvKQEqin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General code for model classifiers"
      ],
      "metadata": {
        "id": "TY-fNDmAWvKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, z_phot, ZA_finkelstein = processed_data()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.45, random_state=42)\n"
      ],
      "metadata": {
        "id": "1Gx_irHnWchb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that this fits the entire data and compares against the teams entire data!"
      ],
      "metadata": {
        "id": "KWdQB8PkpXga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_to_standard_result(model):\n",
        "  model.fit(X, y)\n",
        "  y_pred = model.predict(X)\n",
        "\n",
        "  figure, ax_main = plt.subplots(1, 2, figsize =(14.5, 7.5))\n",
        "\n",
        "  ax_main[0].scatter(y_pred, z_phot, color=\"black\")\n",
        "  ax_main[0].plot([-0.1, 3.5], [-0.1, 3.5], color=\"green\", linestyle=\"--\")\n",
        "  ax_main[0].set_xlabel(\" Model's Prediction \", size=15)\n",
        "  ax_main[0].set_ylabel(\" Z_Phot \", size=15)\n",
        "  ax_main[0].set_title(\" Prediction Against Z_Phot \", size=15)\n",
        "\n",
        "  ax_main[1].scatter(y_pred, ZA_finkelstein, color=\"black\")\n",
        "  ax_main[1].plot([-0.1, 3.5], [-0.1, 3.5], color=\"green\", linestyle=\"--\")\n",
        "  ax_main[1].set_xlabel(\" Model's Prediction \", size=15)\n",
        "  ax_main[1].set_ylabel(\" ZA_finkelstein \", size=15)\n",
        "  ax_main[1].set_title(\" Prediction Against ZA_finkelstein \", size=15)\n",
        "\n",
        "  figure.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "221_iPlho5SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_estimator(model_name, depth_or_neighbor):\n",
        "\n",
        "  if model_name == KNeighborsRegressor:\n",
        "    model = model_name(depth_or_neighbor)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    rms_error = np.sqrt(np.mean( (y_test - y_pred)**2 ))\n",
        "    print(y_pred.shape)\n",
        "\n",
        "    figure, ax_main = plt.subplots(figsize =(9.5, 7.5))\n",
        "    ax_main.scatter(y_test, y_pred, label=f\" \\n neighbors = {depth_or_neighbor} \\n  rms error = {rms_error:.4} \", color=\"black\")\n",
        "    ax_main.plot([-0.1, 3.5], [-0.1, 3.5], color=\"green\", linestyle=\"--\")\n",
        "    ax_main.set_ylabel(\" Predicted Photometric Redshift. \", size=15)\n",
        "    ax_main.set_xlabel(\" True spectroscopic Redshift(z_spec). \", size=15)\n",
        "    ax_main.set_title(\" Predicted photo_z against z_spec. \", size=15)\n",
        "    ax_main.legend(loc=\"best\")\n",
        "\n",
        "    figure.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  else:\n",
        "     model = model_name(max_depth=depth_or_neighbor, random_state=42)\n",
        "     model.fit(X_train, y_train)\n",
        "\n",
        "     y_pred = model.predict(X_test)\n",
        "     rms_error = np.sqrt(np.mean( (y_test - y_pred)**2 ))\n",
        "     print(y_pred.shape)\n",
        "\n",
        "     feature_importance = model.feature_importances_\n",
        "\n",
        "     figure, ax_main = plt.subplots(1,2,figsize =(14.5, 7.5))\n",
        "     ax_main[0].scatter(y_test, y_pred, label=f\" \\n neighbors = {depth_or_neighbor} \\n  rms error = {rms_error:.4} \", color=\"black\")\n",
        "     ax_main[0].plot([-0.1, 3.5], [-0.1, 3.5], color=\"green\", linestyle=\"--\")\n",
        "     ax_main[0].set_ylabel(\" Predicted Photometric Redshift. \", size =15)\n",
        "     ax_main[0].set_xlabel(\" True spectroscopic Redshift(z_spec). \", size =15)\n",
        "     ax_main[0].set_title(\" Predicted photo_z against z_spec. \", size =15 )\n",
        "     ax_main[0].legend(loc=\"best\")\n",
        "\n",
        "     ax_main[1].bar(np.arange(len(feature_importance)), feature_importance, color=\"black\")\n",
        "     ax_main[1].set_ylabel(\" Feature Importance \", size = 15)\n",
        "     ax_main[1].set_xlabel(\" Feature Index in X(fitted Data) \", size=15)\n",
        "     ax_main[1].set_title(\" Feature Importance Plot\", size =15)\n",
        "\n",
        "     figure.tight_layout()\n",
        "     plt.show()\n"
      ],
      "metadata": {
        "id": "SqtuvNDeoxur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(model_name):\n",
        "\n",
        "  max_depth_container = np.arange(1,21)\n",
        "  train_rms_error = []\n",
        "  cross_validation_rms_error = []\n",
        "\n",
        "  for depth in max_depth_container:\n",
        "\n",
        "    if model_name == KNeighborsRegressor:\n",
        "      model = model_name(depth, n_jobs = -1)\n",
        "    elif model_name == DecisionTreeRegressor:\n",
        "      model = model_name(max_depth=depth, random_state = 42)\n",
        "    else:\n",
        "      model = model_name(max_depth=depth, random_state=42, n_jobs=-1)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    # print(y_test_pred.shape)\n",
        "\n",
        "    train_error = np.sqrt(np.mean( (y_train - y_train_pred)**2 ))\n",
        "    cross_validation_error = np.sqrt(np.mean( (y_test - y_test_pred)**2 ))\n",
        "    # print(X)\n",
        "\n",
        "    train_rms_error.append(train_error)\n",
        "    cross_validation_rms_error.append(cross_validation_error)\n",
        "\n",
        "\n",
        "  figure, ax_main = plt.subplots(figsize=(10,7.5))\n",
        "\n",
        "  ax_main.plot(max_depth_container, train_rms_error, label=\"training error\")\n",
        "  ax_main.plot(max_depth_container, cross_validation_rms_error, label=\"cross validation error\")\n",
        "  ax_main.set_xlabel(\"Depth of Tree\", size = 15)\n",
        "  ax_main.set_ylabel(\"Root Mean Square Error\", size =15)\n",
        "  ax_main.set_title(f\" Cross validation for {model_name.__name__}.\", size=15)\n",
        "  ax_main.legend(loc=\"best\", fontsize=10)\n",
        "\n",
        "  # print(train_rms_error)"
      ],
      "metadata": {
        "id": "AwwliA9rau_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally the NMAD estimator."
      ],
      "metadata": {
        "id": "tX6q8B9YVv-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NMAD_calculator(model):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  NMAD = 1.48 * np.median( ( np.abs(y_test - y_pred) )/(1 + y_test) )\n",
        "\n",
        "  return NMAD"
      ],
      "metadata": {
        "id": "tRyiKRQMVzMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeRegressor"
      ],
      "metadata": {
        "id": "c7PdoAXFE1Lk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We show the cross validation result for Decision Tree Refgressor."
      ],
      "metadata": {
        "id": "I8fSC_NNbC4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation(DecisionTreeRegressor)\n"
      ],
      "metadata": {
        "id": "ZNGtqBjqMFAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_depth_estimate = 17\n",
        "\n",
        "model_estimator(DecisionTreeRegressor, best_depth_estimate)"
      ],
      "metadata": {
        "id": "IOaGQN34FZ1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we compute the Normalized Median Absolute Deviation for this model."
      ],
      "metadata": {
        "id": "lkdL-2smT2Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_model = DecisionTreeRegressor(max_depth=best_depth_estimate, random_state=42)\n",
        "decision_tree_NMAD = NMAD_calculator(decision_tree_model)\n",
        "\n",
        "print(f\" The Decision Tree Regressor model has an NMAD of {decision_tree_NMAD:.4}.\")"
      ],
      "metadata": {
        "id": "cMUTk6tRUdxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we compare this result to the standard results by the CEERS team."
      ],
      "metadata": {
        "id": "TkTGeql6qzm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree_model = DecisionTreeRegressor(max_depth=best_depth_estimate, random_state=42)\n",
        "\n",
        "compare_to_standard_result(decision_tree_model)"
      ],
      "metadata": {
        "id": "xL7a_2mtq45Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForestRegressor"
      ],
      "metadata": {
        "id": "utuS8EiWE5Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation(RandomForestRegressor)\n"
      ],
      "metadata": {
        "id": "0k3-Zk7URzIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_depth_estimate = 8\n",
        "\n",
        "model_estimator(RandomForestRegressor, best_depth_estimate)\n"
      ],
      "metadata": {
        "id": "2a7rHU_rHlYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we compute the Normalized Median Absolute Deviation value for this model."
      ],
      "metadata": {
        "id": "OPLJguAqXY_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_model = RandomForestRegressor(max_depth=best_depth_estimate, n_jobs=-1, random_state=42)\n",
        "random_forest_NMAD = NMAD_calculator(random_forest_model)\n",
        "\n",
        "print(f\" The Random Forest Regressor model has an NMAD of {random_forest_NMAD:.4}.\")"
      ],
      "metadata": {
        "id": "-tJpzMz4XgFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we compare the result to the standard result by the CEERS team."
      ],
      "metadata": {
        "id": "EWeWzJKBr81g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_model = RandomForestRegressor(max_depth=best_depth_estimate, n_jobs=-1, random_state=42)\n",
        "\n",
        "compare_to_standard_result(random_forest_model)"
      ],
      "metadata": {
        "id": "lURdy6u2sCBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which is quite excellent indicating much less variability than the prediction of the Decision Tree Regressor Model. So, the Random Forest Regressor model is doing quite a good job."
      ],
      "metadata": {
        "id": "npMAHMg6a6PB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNeighborsRegressor"
      ],
      "metadata": {
        "id": "Aa70RSsOE8ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation for KNeighbor Regressor"
      ],
      "metadata": {
        "id": "CSiB04PnMycw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation(KNeighborsRegressor)"
      ],
      "metadata": {
        "id": "un7mQmkVblpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_neighbor_estimate = 6\n",
        "model_estimator(KNeighborsRegressor, best_neighbor_estimate)\n"
      ],
      "metadata": {
        "id": "Mf-e70F6E_K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we compute the Normalized Median Absolute Deviation for this model."
      ],
      "metadata": {
        "id": "ulKVHH97X_C5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kneighbor_model = KNeighborsRegressor(best_neighbor_estimate, n_jobs=-1)\n",
        "kneighbor_NMAD = NMAD_calculator(kneighbor_model)\n",
        "\n",
        "print(f\" The KNeighbor Regressor model has an NMAD of {kneighbor_NMAD:.4}.\")"
      ],
      "metadata": {
        "id": "kcZ3YzWsYE2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we make a comparison between the predictions of the KNeighborsRegressor Model and the standard result by the CEERS team."
      ],
      "metadata": {
        "id": "OjoISNSLsU5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kneighbor_model = KNeighborsRegressor(best_neighbor_estimate, n_jobs=-1)\n",
        "\n",
        "compare_to_standard_result(kneighbor_model)"
      ],
      "metadata": {
        "id": "3ZVZAmZ7s1iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_337PuqBFMtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}