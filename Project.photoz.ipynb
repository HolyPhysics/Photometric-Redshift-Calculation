{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AS262 - Projects\n",
    "\n",
    "# Photometric Redshift Calculation\n",
    "\n",
    "## Background / Motivation \n",
    "\n",
    "A photometric redshift is an estimate for the recession velocity of a galaxy made without measuring its spectrum.  Instead the technique uses photometry and broad-band colors to estimate the galaxies redshift.  Using photometric redshifts to estimate the distances of faint galaxies has become an integral part of galaxy surveys conducted during recent years. This is driven by the large number of galaxies and their faint fluxes, which have made spectroscopic follow-up infeasible except for a relatively small and bright fraction of the galaxy population. Albeit less precise and less accurate than spectroscopy, photometric redshifts provide a way to estimate distances for galaxies too faint for spectroscopy or samples too large to be practical for complete spectroscopic coverage. \n",
    "\n",
    "## Project Outline: \n",
    "* Use supervised classification to determine the redshift of galaxies based on their broad band photometry.\n",
    "\n",
    "\n",
    "* The data used for this project will come from the [CEERS surey](https://ceers.github.io), which imaged a region of sky known as the Extended Groth Strip with JWST.  The photometry data is stored in an hdf5 file (similar to the fits table we used in Lecture 3 UVJ exercise, and read in with exactly the same routine, using astropy.table.Table).  This file will be made available on Filer.  Please note that the photometry data has not been published, so it should be considered proprietary for the time being.  I am allowing students to use this data since I am a member of the CEERS collaboration, and you can gain access to it through me.\n",
    "\n",
    "\n",
    "* You'll most likely want to limit your analysis to relatively bright and/or massive galaxies.  This might mean only working with galaxies whose F356W magnitude is less than 26.5 and/or mass greater than $10^8 M_\\odot$.  You should vary these cuts to determine how they affect the final results.\n",
    "\n",
    "\n",
    "* Youâ€™ll need to group the photometry as features in a single `X` array in the format that Scikit-Learn wants and then split the array into a training and test dataset using the `split_samples` routine, which we encountered in Lecture 16. The \"known\" redshifts come from spectroscopy, given in the table as 'z_spec'.  Note that not all galaxies have spectroscopy, so your training set can only use a subset of the full dataset.  You could perform cross-validation on some subset of this, and then apply your model to the remaining data and compare to the team's photometric redshifts (given as 'ZA_finkelstein' or 'z_phot').\n",
    "\n",
    "\n",
    "* Try **at least two** supervised classification algorithms and compare their effectiveness by plotting the true redshift against the predicted redshift.  The plot should look something similar to this (although the table I'm providing you doesn't list different quality flags for the spectroscopic redshifts, so all data points would be the same color):\n",
    "\n",
    "\n",
    "<img src=https://www.colby.edu/physics/faculty/mcgrath/AS262/photoz.png width=\"500\">\n",
    "\n",
    "\n",
    "* A quantitative measure of how well the classifier is working can be calculated using the Normalized Median Absolute Deviation:\n",
    "\n",
    "$$ \\sigma_{\\rm NMAD} = 1.48\\times {\\rm median}\\left(\\frac{|\\Delta z|}{1+z_{rm true}}\\right) $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Potential classification algorithms include:\n",
    "    * Decision Tree Classifier (`sklearn.tree.DecisionTreeRegressor`)\n",
    "    * Random Forest Classifier (`sklearn.ensemble.RandomForestRegressor`)\n",
    "    * K-Neighbors Classifier (`sklearn.neighbors.KNeighborsRegressor`)\n",
    "    * Support Vector Machine (`sklearn.svm.SVR`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Here's an example of using a Decision Tree Regression to calculate the photometric redshift of galaxies in the SDSS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Jake VanderPlas\n",
    "# License: BSD\n",
    "#   The figure produced by this code is published in the textbook\n",
    "#   \"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)\n",
    "#   For more information, see http://astroML.github.com\n",
    "#   To report a bug or issue, use the following forum:\n",
    "#    https://groups.google.com/forum/#!forum/astroml-general\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns; sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from astroML.datasets import fetch_sdss_specgals\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=True)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Fetch data and prepare it for the computation\n",
    "data = fetch_sdss_specgals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put magnitudes in a matrix\n",
    "mag = np.vstack([data['modelMag_%s' % f] for f in 'ugriz']).T\n",
    "z = data['z']\n",
    "\n",
    "# train on ~60,000 points\n",
    "mag_train = mag[::10]\n",
    "z_train = z[::10]\n",
    "\n",
    "# test on ~6,000 separate points\n",
    "mag_test = mag[1::100]\n",
    "z_test = z[1::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# Compute the cross-validation scores for several tree depths\n",
    "depth = np.arange(1, 21)\n",
    "rms_test = np.zeros(len(depth))\n",
    "rms_train = np.zeros(len(depth))\n",
    "i_best = 0\n",
    "z_fit_best = None\n",
    "\n",
    "for i, d in enumerate(depth):\n",
    "    clf = DecisionTreeRegressor(max_depth=d, random_state=0)\n",
    "    clf.fit(mag_train, z_train)\n",
    "\n",
    "    z_fit_train = clf.predict(mag_train)\n",
    "    z_fit = clf.predict(mag_test)\n",
    "    rms_train[i] = np.mean(np.sqrt((z_fit_train - z_train) ** 2))\n",
    "    rms_test[i] = np.mean(np.sqrt((z_fit - z_test) ** 2))\n",
    "\n",
    "    if rms_test[i] <= rms_test[i_best]:\n",
    "        i_best = i\n",
    "        z_fit_best = z_fit\n",
    "\n",
    "best_depth = depth[i_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(wspace=0.25,\n",
    "                    left=0.1, right=0.95,\n",
    "                    bottom=0.15, top=0.9)\n",
    "\n",
    "# first panel: cross-validation\n",
    "ax = fig.add_subplot(121)\n",
    "ax.plot(depth, rms_test, '-k', label='cross-validation')\n",
    "ax.plot(depth, rms_train, '--k', label='training set')\n",
    "ax.set_xlabel('depth of tree', size=20)\n",
    "ax.set_ylabel('rms error', size=20)\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.01))\n",
    "ax.set_xlim(0, 21)\n",
    "ax.set_ylim(0.009,  0.04)\n",
    "ax.legend(loc=1, fontsize='large')\n",
    "\n",
    "# second panel: best-fit results\n",
    "ax = fig.add_subplot(122)\n",
    "edges = np.linspace(z_test.min(), z_test.max(), 101)\n",
    "H, zs_bins, zp_bins = np.histogram2d(z_test, z_fit_best, bins=edges)\n",
    "ax.imshow(H.T, origin='lower', interpolation='nearest', aspect='auto', \n",
    "           extent=[zs_bins[0], zs_bins[-1], zs_bins[0], zs_bins[-1]],\n",
    "           cmap=plt.cm.binary)\n",
    "ax.plot([-0.1, 0.4], [-0.1, 0.4], ':k')\n",
    "ax.text(0.04, 0.96, \"depth = %i\\nrms = %.3f\" % (best_depth, rms_test[i_best]),\n",
    "        ha='left', va='top', transform=ax.transAxes, size=12)\n",
    "ax.set_xlabel(r'$z_{\\rm true}$', size=20)\n",
    "ax.set_ylabel(r'$z_{\\rm fit}$', size=20)\n",
    "\n",
    "ax.set_xlim(-0.02, 0.4001)\n",
    "ax.set_ylim(-0.02, 0.4001)\n",
    "ax.xaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "ax.yaxis.set_major_locator(plt.MultipleLocator(0.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preliminaries to get you started using the CEERS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "h5py is required to read and write HDF5 files",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m photometry_file = \u001b[33m\"\u001b[39m\u001b[33mceers_all_v0.51_eazy.hdf5\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Note, you'll need to edit this path to wherever you store the data.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m photometry = \u001b[43mTable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphotometry_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m photometry\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/astropy/table/connect.py:62\u001b[39m, in \u001b[36mTableRead.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     59\u001b[39m units = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33munits\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     60\u001b[39m descriptions = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdescriptions\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# For some readers (e.g., ascii.ecsv), the returned `out` class is not\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# guaranteed to be the same as the desired output `cls`.  If so,\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# try coercing to desired class without copying (io.registry.read\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# would normally do a copy).  The normal case here is swapping\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Table <=> QTable.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out.\u001b[34m__class__\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/astropy/io/registry/core.py:221\u001b[39m, in \u001b[36mUnifiedInputRegistry.read\u001b[39m\u001b[34m(self, cls, format, cache, *args, **kwargs)\u001b[39m\n\u001b[32m    218\u001b[39m         kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m\"\u001b[39m: path})\n\u001b[32m    220\u001b[39m reader = \u001b[38;5;28mself\u001b[39m.get_reader(\u001b[38;5;28mformat\u001b[39m, \u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m data = \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mcls\u001b[39m):\n\u001b[32m    224\u001b[39m     \u001b[38;5;66;03m# User has read with a subclass where only the parent class is\u001b[39;00m\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# registered.  This returns the parent class, so try coercing\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# to desired subclass.\u001b[39;00m\n\u001b[32m    227\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages/astropy/io/misc/hdf5.py:88\u001b[39m, in \u001b[36mread_table_hdf5\u001b[39m\u001b[34m(input, path, character_as_bytes)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03mRead a Table object from an HDF5 file.\u001b[39;00m\n\u001b[32m     69\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33;03m    If `False` then Table columns are converted to unicode.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m HAS_H5PY:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mh5py is required to read and write HDF5 files\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mh5py\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# This function is iterative, and only gets to writing the file when\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m# the input is an hdf5 Group. Moreover, the input variable is changed in\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# place.\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Here, we save its value to be used at the end when the conditions are\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# right.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: h5py is required to read and write HDF5 files"
     ]
    }
   ],
   "source": [
    "photometry_file = \"ceers_all_v0.51_eazy.hdf5\" # Note, you'll need to edit this path to wherever you store the data.\n",
    "photometry = Table.read(photometry_file)\n",
    "photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'photometry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Columns of interest in the photometry file:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m log_mass = \u001b[43mphotometry\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mfast_lmass\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# To calculate magnitudes, you need the zeropoint (31.4), since the catalog lists fluxes in units of nano-Jansky:\u001b[39;00m\n\u001b[32m      4\u001b[39m f356w_mag = -\u001b[32m2.5\u001b[39m*np.log10(phot[\u001b[33m'\u001b[39m\u001b[33mFLUX_356\u001b[39m\u001b[33m'\u001b[39m])+\u001b[32m31.4\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'photometry' is not defined"
     ]
    }
   ],
   "source": [
    "# Columns of interest in the photometry file:\n",
    "log_mass = photometry['fast_lmass']\n",
    "# To calculate magnitudes, you need the zeropoint (31.4), since the catalog lists fluxes in units of nano-Jansky:\n",
    "f356w_mag = -2.5*np.log10(photometry['FLUX_356'])+31.4\n",
    "# It's the same zeropoint for all JWST filters: F115W, F150W, F200W, F277W, F356W, F410M, F444W.  There is also HST photometry data in this table.  Come talk to me to get help with using these.\n",
    "\n",
    "# photometric redshfits (two different sets done by two different CEERS team members):\n",
    "z_phot = photometry['z_phot']\n",
    "# or, alternatively you could use a different set of phot-z's:\n",
    "z_phot_finkelstein = photometry['ZA_finkelstein']\n",
    "\n",
    "#Spectroscopic redshifts (values of -99 or -1 should be excluded):\n",
    "z_spec = photometry['z_spec']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
